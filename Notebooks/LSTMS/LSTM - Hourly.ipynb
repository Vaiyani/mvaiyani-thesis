{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c667046e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import save_model, model_from_json, Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow import keras\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras.models import load_model\n",
    "from plotly.subplots import make_subplots\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from typing import Union\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9ff041",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/cleaned_data.csv')\n",
    "data = df['close'].values\n",
    "data = data.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44951d5b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def min_max_scale(train: np.array, val:np.array, test: np.array) -> Union[MinMaxScaler, np.array, np.array, np.array]:\n",
    "    \"\"\" Tranform the train and test data into min max scale of train data\"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler = scaler.fit(train)\n",
    "    train_normalized = scaler.transform(train)\n",
    "    test_normalized = scaler.transform(test)\n",
    "    val_normalized = scaler.transform(val)\n",
    "    return scaler, train_normalized, val_normalized, test_normalized\n",
    "\n",
    "def data_divider(data: np.array, threshold: int):\n",
    "    \"\"\" This functions divideds the data (close price) into 80 20 ration for test and train data \"\"\"\n",
    "    train_test_divider = int(len(data)*threshold)\n",
    "    training_data, testing_data = data[:train_test_divider], data[train_test_divider:]\n",
    "    return training_data, testing_data\n",
    "\n",
    "def sliding_window(data: [], window_length: int, pred_len: int = 1) -> Union[np.array, np.array]:\n",
    "    \"\"\" \n",
    "    This function creates a sliding window pattern from the data given and window length given.\n",
    "    For example:\n",
    "    Data = [[1],[2],[3],[4],[5],[6]]\n",
    "    sliding window = 2\n",
    "    pred_len = 1\n",
    "    X = [[[1],[2]],[[2],[3]],[[3],[4]],[[4],[5]]]\n",
    "    Y = [[3],[4],[5],[6]]\n",
    "    \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(data) - window_length):\n",
    "        input_end = i + window_length\n",
    "        output_end = input_end + pred_len\n",
    "        if output_end > len(data):\n",
    "            break\n",
    "        X.append(data[i: input_end])\n",
    "        Y.append(data[input_end: output_end])\n",
    "    \n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def model_builder(hp):\n",
    "    \"\"\" Keras hyper paramter tuner model builder\"\"\"\n",
    "    hp_dropout = hp.Choice('dropout', values=[0.05, 0.1, 0.2])  \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hp.Int('first_layer_neurons', min_value=32, max_value=512, step=32), return_sequences=True))\n",
    "    for i in range(hp.Int('n_layers', 1, 4)):\n",
    "        model.add(LSTM(hp.Int(f'lstm_{i}_units',min_value=32,max_value=512,step=32),return_sequences=True))\n",
    "    model.add(Dropout(hp_dropout))\n",
    "    model.add(LSTM(hp.Int('second_layer_neurons', min_value=32, max_value=512, step=32)))\n",
    "    model.add(Dense(1))\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='mse',\n",
    "                  metrics='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "def show_best_hyperparamters(best_hps):\n",
    "    print('Best Hyper Parameters\\n')\n",
    "    print('Layer 1 neuron: ', best_hps.get('first_layer_neurons'))\n",
    "    print('Layer 2 neuron: ' , best_hps.get('second_layer_neurons'))\n",
    "    print('n_layers: ' , best_hps.get('n_layer'))\n",
    "    print('learning_rate: ', best_hps.get('learning_rate'))\n",
    "    print('Dropout rate: ', best_hps.get('dropout'))\n",
    "    \n",
    "def calculate_metrics(test: np.ndarray, predict: np.ndarray) -> float:\n",
    "    \"\"\".\"\"\"\n",
    "    RMSE = mean_squared_error(test.flatten(), predict.flatten(), squared=False)\n",
    "    MSE = mean_squared_error(test.flatten(), predict.flatten())\n",
    "    MAE = mean_absolute_error(test.flatten(), predict.flatten())\n",
    "    MAPE = mean_absolute_percentage_error(test.flatten(), predict.flatten())\n",
    "    r2 = r2_score(test.flatten(), predict.flatten())\n",
    "    print('mse: {}, mae: {}, rmse: {}, mape: {}, R2: {}'.format(MSE, MAE, RMSE, MAPE, r2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33536623",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lookback = 3\n",
    "pred_len = 1\n",
    "train, test = data_divider(data, 0.8)\n",
    "val, test = data_divider(test, 0.5)\n",
    "scaler, train_normalized, val_normalized, test_normalized = min_max_scale(train, val, test)\n",
    "x_train, y_train = sliding_window(train_normalized, lookback, pred_len)\n",
    "x_val, y_val = sliding_window(val_normalized, lookback, pred_len)\n",
    "x_test, y_test = sliding_window(test_normalized, lookback, pred_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605b7f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 24m 02s]\n",
      "val_mse: 0.000210985861485824\n",
      "\n",
      "Best val_mse So Far: 4.985070336260833e-05\n",
      "Total elapsed time: 00h 24m 02s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "tanh              |tanh              |activationfunc\n",
      "0.2               |0.05              |dropout\n",
      "256               |192               |first_layer_neurons\n",
      "2                 |3                 |n_layers\n",
      "224               |64                |lstm_0_units\n",
      "64                |256               |second_layer_neurons\n",
      "0.01              |0.01              |learning_rate\n",
      "384               |32                |lstm_1_units\n",
      "352               |32                |lstm_2_units\n",
      "\n",
      "Epoch 1/100\n",
      "  67/1032 [>.............................] - ETA: 3:02 - loss: 0.1886 - mse: 0.1886"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(model_builder, objective='val_mse', max_trials=30, directory='my_dir', project_name='intro_to_kt2')\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner.search(x_train, y_train, epochs=100, validation_data=(x_val,y_val), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ee294",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "show_best_hyperparamters(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f08490f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    \n",
    "#     np.random.seed(1234)\n",
    "#     tf.random.set_seed(1234)\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(100, activation= 'relu', return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100, activation= 'relu'))\n",
    "    model.add(Dense(pred_len))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
    "                  loss='mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b15b48f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training.py\", line 853, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training.py\", line 842, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training.py\", line 835, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training.py\", line 787, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1020, in __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 266, in assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer sequential: expected shape=(None, None, 4), found shape=(None, 3, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# stop_training_early = keras.callbacks.EarlyStopping()\u001b[39;00m\n\u001b[0;32m      6\u001b[0m stop_training_early \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstop_training_early\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstm\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstm\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1130\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training.py\", line 853, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training.py\", line 842, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training.py\", line 835, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\training.py\", line 787, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1020, in __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    File \"C:\\Users\\Athra\\anaconda3\\envs\\lstm\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 266, in assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer sequential: expected shape=(None, None, 4), found shape=(None, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the best hp.\n",
    "# model = model_builder(best_hps)\n",
    "\n",
    "model = model()\n",
    "# stop_training_early = keras.callbacks.EarlyStopping()\n",
    "stop_training_early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience = 2)\n",
    "history = model.fit(x_train, y_train, epochs=1 , verbose=1, shuffle=False, validation_data = (x_val, y_val), callbacks=[stop_training_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ccee19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d293f48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa4183",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Build the model with the best hp.\n",
    "# model = model_builder(best_hps)\n",
    "\n",
    "model = model()\n",
    "# stop_training_early = keras.callbacks.EarlyStopping()\n",
    "stop_training_early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience = 2)\n",
    "history = model.fit(x_train, y_train, epochs=1 , verbose=1, shuffle=False, validation_data = (x_val, y_val), callbacks=[stop_training_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7639d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f62473",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c403a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Build the model with the best hp.\n",
    "# model = model_builder(best_hps)\n",
    "\n",
    "model = model()\n",
    "# stop_training_early = keras.callbacks.EarlyStopping()\n",
    "stop_training_early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience = 2)\n",
    "history = model.fit(x_train, y_train, epochs=1 , verbose=1, shuffle=False, validation_data = (x_val, y_val), callbacks=[stop_training_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e96d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a1c946-eef6-4fe1-8c98-2d057bd865c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb26b0c0-e47d-4296-87f4-ee94540a3dee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1032 [==============================] - 13s 10ms/step - loss: 0.0330 - val_loss: 0.1646\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the best hp.\n",
    "# model = model_builder(best_hps)\n",
    "\n",
    "model = model()\n",
    "# stop_training_early = keras.callbacks.EarlyStopping()\n",
    "stop_training_early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience = 2)\n",
    "history = model.fit(x_train, y_train, epochs=1 , verbose=1, shuffle=False, validation_data = (x_val, y_val), callbacks=[stop_training_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee699871",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 6, 100)            40800     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 100)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 121,402\n",
      "Trainable params: 121,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9dd4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c7cde-0d86-4b96-bf6f-c229eb235023",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = load_model('saved_model/hourly_model')\n",
    "# model.save('saved_model/hourly_100_model')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6abba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a2673-57ef-4ff4-95ae-eb9203e38c96",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d45e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebff6bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa03fdfb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def evaluate_rmse(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        # calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "        # store\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores\n",
    "\n",
    "def evaluate_mae(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mse\n",
    "        mae = mean_absolute_error(actual[:, i], predicted[:, i])\n",
    "        scores.append(mae)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += abs(actual[row, col] - predicted[row, col])\n",
    "    score = s / (actual.shape[0] * actual.shape[1])\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e11d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_rmse(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b073ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_mae(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bb682",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "calculate_metrics(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec69f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # plt.plot(y_test.flatten(), label='test')\n",
    "# # plt.plot(y_predict.flatten(), 'r-', label='predict')\n",
    "# # plt.legend()\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(y = y_test.flatten(), name = 'Actual'))\n",
    "# fig.add_trace(go.Scatter(y = y_predict.flatten(), name = 'Predict'))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m94"
  },
  "kernelspec": {
   "display_name": "Python [conda env:lstm]",
   "language": "python",
   "name": "conda-env-lstm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
