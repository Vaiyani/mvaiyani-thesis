# Thesis

This repo is for the study of master thesis. 
It explores the various versions of Transformers, LSTMS and ARIMA to understand which architecture is more robust towards long range dependency modelling for a dataset with no periodicity. The dataset used is the bitcoin dataset from 2017 till 2022.

References:
- [Transformer](https://arxiv.org/abs/1706.03762) (NeuIPS 2017)
- [Informer](https://arxiv.org/abs/2012.07436) (AAAI 2021 Best paper)
- [Autoformer](https://arxiv.org/abs/2106.13008) (NeuIPS 2021)








